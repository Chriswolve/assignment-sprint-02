{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d3c07ee-c3bf-4530-812a-36405502b38d",
   "metadata": {
    "id": "9d3c07ee-c3bf-4530-812a-36405502b38d"
   },
   "source": [
    "# AnyoneAI - Sprint Project 02\n",
    "> Home Credit Default Risk\n",
    "\n",
    "You've been learning a lot about Machine Learning Algorithms, now we you're gonna be asked to put it all togheter. \n",
    "\n",
    "You will create a complete pipeline to preprocess the data, train your model and then predict values for the [Home Credit Default Risk](https://www.kaggle.com/competitions/home-credit-default-risk/) Kaggle competition.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e396c950-04b0-453e-b930-a22a96cee2d1",
   "metadata": {
    "id": "e396c950-04b0-453e-b930-a22a96cee2d1"
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This is a binary Classification task: we want to predict whether the person applying for a home credit will be able to repay their debt or not. Our model will have to predict a 1 indicating the client will have payment difficulties: he/she will have late payment of more than X days on at least one of the first Y installments of the loan in our sample, 0 in all other cases.\n",
    "\n",
    "The dataset is composed of multiple files with different information about loans taken. In this project, we will work exclusively with the primary files: `application_train_aai.csv` and `application_test_aai.csv`.\n",
    "\n",
    "We will use [Area Under the ROC Curve](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=es_419) as the evaluation metric, so our models will have to return the probabilities that a loan is not paid for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "OzQjTwlkUT0C",
   "metadata": {
    "executionInfo": {
     "elapsed": 2252,
     "status": "ok",
     "timestamp": 1670194396248,
     "user": {
      "displayName": "Jose Luis",
      "userId": "17952480099147442429"
     },
     "user_tz": 180
    },
    "id": "OzQjTwlkUT0C"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from imblearn.combine import SMOTETomek\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src import config, data_utils, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jrkLdOJnWoSS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1670195316027,
     "user": {
      "displayName": "Jose Luis",
      "userId": "17952480099147442429"
     },
     "user_tz": 180
    },
    "id": "jrkLdOJnWoSS",
    "outputId": "ce9f5ee1-6ed0-4b6f-d8f5-37d38b4e4773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: app_train shape is correct!\n",
      "Success: app_train type is correct!\n",
      "Success: app_test shape is correct!\n",
      "Success: app_test type is correct!\n"
     ]
    }
   ],
   "source": [
    "app_train, app_test, columns_description = data_utils.get_datasets()\n",
    "\n",
    "\n",
    "if app_train.shape == (246008, 122):\n",
    "    print(\"Success: app_train shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Train dataset shape is incorrect, please review your code\")\n",
    "\n",
    "if isinstance(app_train, pd.DataFrame):\n",
    "    print(\"Success: app_train type is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Train dataset type is incorrect, please review your code\")\n",
    "\n",
    "if app_test.shape == (61503, 122):\n",
    "    print(\"Success: app_test shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Test dataset shape is incorrect, please review your code\")\n",
    "\n",
    "if isinstance(app_test, pd.DataFrame):\n",
    "    print(\"Success: app_test type is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Test dataset type is incorrect, please review your code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5F5UeGj1aNvJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1670195363853,
     "user": {
      "displayName": "Jose Luis",
      "userId": "17952480099147442429"
     },
     "user_tz": 180
    },
    "id": "5F5UeGj1aNvJ",
    "outputId": "6ce8ac80-c09c-43dd-a537-cc7b25220efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: X_train shape is correct!\n",
      "Success: X_train type is correct!\n",
      "Success: y_train shape is correct!\n",
      "Success: X_test shape is correct!\n",
      "Success: X_test type is correct!\n",
      "Success: y_test shape is correct!\n"
     ]
    }
   ],
   "source": [
    "# Now we execute the function above to get the result\n",
    "X_train, y_train, X_test, y_test = data_utils.get_feature_target(app_train, app_test)\n",
    "\n",
    "\n",
    "if X_train.shape == (246008, 121):\n",
    "    print(\"Success: X_train shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"X_train dataset shape is incorrect, please review your code\")\n",
    "\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    print(\"Success: X_train type is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Train dataset type is incorrect, please review your code\")\n",
    "\n",
    "if y_train.shape == (246008,) or y_train.shape == (246008, 1):\n",
    "    print(\"Success: y_train shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Train labels shape is incorrect, please review your code\")\n",
    "\n",
    "if X_test.shape == (61503, 121):\n",
    "    print(\"Success: X_test shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Test dataset shape is incorrect, please review your code\")\n",
    "\n",
    "if isinstance(X_test, pd.DataFrame):\n",
    "    print(\"Success: X_test type is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Test dataset type is incorrect, please review your code\")\n",
    "\n",
    "if y_test.shape == (61503,) or y_test.shape == (61503, 1):\n",
    "    print(\"Success: y_test shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Test labels shape is incorrect, please review your code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec771222",
   "metadata": {},
   "source": [
    "**Don't change anything in this cell, just make it run correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d31b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: X_train shape is correct!\n",
      "Success: X_train type is correct!\n",
      "Success: y_train shape is correct!\n",
      "Success: X_test shape is correct!\n",
      "Success: X_test type is correct!\n",
      "Success: y_test shape is correct!\n"
     ]
    }
   ],
   "source": [
    "# Now we execute the function above to get the result\n",
    "X_train, X_val, y_train, y_val = data_utils.get_train_val_sets(X_train, y_train)\n",
    "\n",
    "\n",
    "if X_train.shape == (196806, 121):\n",
    "    print(\"Success: X_train shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"X_train dataset shape is incorrect, please review your code\")\n",
    "\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    print(\"Success: X_train type is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Train dataset type is incorrect, please review your code\")\n",
    "\n",
    "if y_train.shape == (196806,) or y_train.shape == (196806, 1):\n",
    "    print(\"Success: y_train shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Train labels shape is incorrect, please review your code\")\n",
    "\n",
    "if X_val.shape == (49202, 121):\n",
    "    print(\"Success: X_test shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Test dataset shape is incorrect, please review your code\")\n",
    "\n",
    "if isinstance(X_val, pd.DataFrame):\n",
    "    print(\"Success: X_test type is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Test dataset type is incorrect, please review your code\")\n",
    "\n",
    "if y_val.shape == (49202,) or y_val.shape == (49202, 1):\n",
    "    print(\"Success: y_test shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Test labels shape is incorrect, please review your code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mMkqwi0gd7a8",
   "metadata": {
    "id": "mMkqwi0gd7a8"
   },
   "source": [
    "**Don't change anything in this cell, just make it run correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "whWcb5jtcyYe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1670195395495,
     "user": {
      "displayName": "Jose Luis",
      "userId": "17952480099147442429"
     },
     "user_tz": 180
    },
    "id": "whWcb5jtcyYe",
    "outputId": "5bb07f0e-a0b6-4773-94b1-97c5f2ccd053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input train data shape:  (196806, 121)\n",
      "Input val data shape:  (49202, 121)\n",
      "Input test data shape:  (61503, 121) \n",
      "\n",
      "Creating essential new features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/usuario/Sites/anyone/assignment-sprint-02/src/preprocessing.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  working_train_df[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
      "/Users/usuario/Sites/anyone/assignment-sprint-02/src/preprocessing.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  working_val_df[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
      "/Users/usuario/Sites/anyone/assignment-sprint-02/src/preprocessing.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  working_test_df[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features...\n",
      "Imputing missing values...\n",
      "Current feature count: 248\n",
      "No target available. Taking first 246 features.\n",
      "Scaling features...\n",
      "Processed train data shape:  (196806, 246)\n",
      "Processed val data shape:  (49202, 246)\n",
      "Processed test data shape:  (61503, 246) \n",
      "\n",
      "Success: train_data shape is correct!\n",
      "Success: train_data type is correct!\n",
      "Success: val_data shape is correct!\n",
      "Success: val_data type is correct!\n",
      "Success: test_data shape is correct!\n",
      "Success: test_data type is correct!\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = preprocessing.preprocess_data(X_train, X_val, X_test)\n",
    "\n",
    "\n",
    "if train_data.shape == (196806, 246):\n",
    "    print(\"Success: train_data shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"train_data dataset shape is incorrect, please review your code\")\n",
    "\n",
    "if isinstance(train_data, np.ndarray):\n",
    "    print(\"Success: train_data type is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Train dataset type is incorrect, please review your code\")\n",
    "\n",
    "if val_data.shape == (49202, 246):\n",
    "    print(\"Success: val_data shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"val_data dataset shape is incorrect, please review your code\")\n",
    "\n",
    "if isinstance(val_data, np.ndarray):\n",
    "    print(\"Success: val_data type is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Validation dataset type is incorrect, please review your code\")\n",
    "\n",
    "if test_data.shape == (61503, 246):\n",
    "    print(\"Success: test_data shape is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"test_data dataset shape is incorrect, please review your code\")\n",
    "\n",
    "if isinstance(test_data, np.ndarray):\n",
    "    print(\"Success: test_data type is correct!\")\n",
    "else:\n",
    "    raise ValueError(\"Test dataset type is incorrect, please review your code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5df1e8-1f03-4f14-9dbd-292d3b84859d",
   "metadata": {
    "id": "2f5df1e8-1f03-4f14-9dbd-292d3b84859d"
   },
   "source": [
    "## 3. Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb84a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "# Ejemplo: Datos de entrada\n",
    "X = train_data  # Características\n",
    "y = y_train     # Etiquetas/target\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "folds = list(kf.split(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7944acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)  \n",
    "y = pd.Series(y)    \n",
    "# Seleccionar el cuarto fold (índice 3 en Python)\n",
    "train_idx, val_idx = folds[3]\n",
    "X_train_fold, y_train_fold = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_val_fold, y_val_fold = X.iloc[val_idx], y.iloc[val_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d448f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.grid_search import grid_search\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 200, 300],           \n",
    "    'max_depth': [8, 10, 12],                     \n",
    "    'min_samples_split': [2, 3, 5],              \n",
    "    'min_samples_leaf': [1, 2],                  \n",
    "    'max_features': [0.5, 0.6, 0.7],         \n",
    "    'class_weight': ['balanced', {0: 1, 1: 8}, {0: 1, 1: 12}]  \n",
    "}\n",
    "    # total combinations = 2 * 2 * 3 * 3 * 2 * 3 = 216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13351bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for instance 1\n",
      "Evaluando combinaciones 0 a 60 (total: 61)\n",
      "✓ Data loaded - Train: (157445, 246), Val: (39361, 246)\n",
      "\n",
      "Starting process to instance: 01 with 61 combinations...\n",
      "\n",
      " Evaluate combination: 01/61 (global 0):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.5\n",
      "  class_weight: balanced\n",
      " Training time: 226.99 seconds\n",
      " ROC AUC Score (train): 0.7846 \n",
      " ROC AUC Score (Test): 0.7387 \n",
      " Difference AUC: 0.0459 \n",
      " F1 Score: 0.2627 \n",
      " Precision Score: 0.1666 \n",
      " Recall Score: 0.6204 \n",
      " New model found! (F1: 0.2627)\n",
      "\n",
      " Evaluate combination: 02/61 (global 1):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.5\n",
      "  class_weight: {0: 1, 1: 8}\n",
      " Training time: 228.36 seconds\n",
      " ROC AUC Score (train): 0.7827 \n",
      " ROC AUC Score (Test): 0.7381 \n",
      " Difference AUC: 0.0446 \n",
      " F1 Score: 0.2830 \n",
      " Precision Score: 0.2008 \n",
      " Recall Score: 0.4789 \n",
      " New model found! (F1: 0.2830)\n",
      "\n",
      " Evaluate combination: 03/61 (global 2):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.5\n",
      "  class_weight: {0: 1, 1: 12}\n",
      " Training time: 227.54 seconds\n",
      " ROC AUC Score (train): 0.7839 \n",
      " ROC AUC Score (Test): 0.7384 \n",
      " Difference AUC: 0.0455 \n",
      " F1 Score: 0.2578 \n",
      " Precision Score: 0.1618 \n",
      " Recall Score: 0.6343 \n",
      "\n",
      " Evaluate combination: 04/61 (global 3):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.6\n",
      "  class_weight: balanced\n",
      " Training time: 267.52 seconds\n",
      " ROC AUC Score (train): 0.7854 \n",
      " ROC AUC Score (Test): 0.7386 \n",
      " Difference AUC: 0.0468 \n",
      " F1 Score: 0.2627 \n",
      " Precision Score: 0.1666 \n",
      " Recall Score: 0.6204 \n",
      "\n",
      " Evaluate combination: 05/61 (global 4):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.6\n",
      "  class_weight: {0: 1, 1: 8}\n",
      " Training time: 267.84 seconds\n",
      " ROC AUC Score (train): 0.7840 \n",
      " ROC AUC Score (Test): 0.7380 \n",
      " Difference AUC: 0.0460 \n",
      " F1 Score: 0.2825 \n",
      " Precision Score: 0.2007 \n",
      " Recall Score: 0.4767 \n",
      "\n",
      " Evaluate combination: 06/61 (global 5):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.6\n",
      "  class_weight: {0: 1, 1: 12}\n",
      " Training time: 268.96 seconds\n",
      " ROC AUC Score (train): 0.7856 \n",
      " ROC AUC Score (Test): 0.7385 \n",
      " Difference AUC: 0.0471 \n",
      " F1 Score: 0.2604 \n",
      " Precision Score: 0.1635 \n",
      " Recall Score: 0.6391 \n",
      "\n",
      " Evaluate combination: 07/61 (global 6):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.7\n",
      "  class_weight: balanced\n",
      " Training time: 312.76 seconds\n",
      " ROC AUC Score (train): 0.7861 \n",
      " ROC AUC Score (Test): 0.7392 \n",
      " Difference AUC: 0.0469 \n",
      " F1 Score: 0.2643 \n",
      " Precision Score: 0.1679 \n",
      " Recall Score: 0.6213 \n",
      "\n",
      " Evaluate combination: 08/61 (global 7):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.7\n",
      "  class_weight: {0: 1, 1: 8}\n",
      " Training time: 314.21 seconds\n",
      " ROC AUC Score (train): 0.7849 \n",
      " ROC AUC Score (Test): 0.7382 \n",
      " Difference AUC: 0.0468 \n",
      " F1 Score: 0.2832 \n",
      " Precision Score: 0.2021 \n",
      " Recall Score: 0.4732 \n",
      " New model found! (F1: 0.2832)\n",
      "\n",
      " Evaluate combination: 09/61 (global 8):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.7\n",
      "  class_weight: {0: 1, 1: 12}\n",
      " Training time: 313.04 seconds\n",
      " ROC AUC Score (train): 0.7865 \n",
      " ROC AUC Score (Test): 0.7381 \n",
      " Difference AUC: 0.0484 \n",
      " F1 Score: 0.2594 \n",
      " Precision Score: 0.1630 \n",
      " Recall Score: 0.6346 \n",
      "\n",
      " Evaluate combination: 010/61 (global 9):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 2\n",
      "  max_features: 0.5\n",
      "  class_weight: balanced\n",
      " Training time: 227.52 seconds\n",
      " ROC AUC Score (train): 0.7841 \n",
      " ROC AUC Score (Test): 0.7385 \n",
      " Difference AUC: 0.0457 \n",
      " F1 Score: 0.2618 \n",
      " Precision Score: 0.1659 \n",
      " Recall Score: 0.6200 \n",
      "\n",
      " Evaluate combination: 011/61 (global 10):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 2\n",
      "  max_features: 0.5\n",
      "  class_weight: {0: 1, 1: 8}\n",
      " Training time: 224.80 seconds\n",
      " ROC AUC Score (train): 0.7824 \n",
      " ROC AUC Score (Test): 0.7382 \n",
      " Difference AUC: 0.0443 \n",
      " F1 Score: 0.2832 \n",
      " Precision Score: 0.2012 \n",
      " Recall Score: 0.4783 \n",
      " New model found! (F1: 0.2832)\n",
      "\n",
      " Evaluate combination: 012/61 (global 11):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 2\n",
      "  max_features: 0.5\n",
      "  class_weight: {0: 1, 1: 12}\n",
      " Training time: 226.41 seconds\n",
      " ROC AUC Score (train): 0.7839 \n",
      " ROC AUC Score (Test): 0.7385 \n",
      " Difference AUC: 0.0454 \n",
      " F1 Score: 0.2588 \n",
      " Precision Score: 0.1623 \n",
      " Recall Score: 0.6391 \n",
      "\n",
      " Evaluate combination: 013/61 (global 12):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 2\n",
      "  max_features: 0.6\n",
      "  class_weight: balanced\n",
      " Training time: 269.35 seconds\n",
      " ROC AUC Score (train): 0.7852 \n",
      " ROC AUC Score (Test): 0.7385 \n",
      " Difference AUC: 0.0467 \n",
      " F1 Score: 0.2608 \n",
      " Precision Score: 0.1653 \n",
      " Recall Score: 0.6169 \n",
      "\n",
      " Evaluate combination: 014/61 (global 13):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 2\n",
      "  max_features: 0.6\n",
      "  class_weight: {0: 1, 1: 8}\n",
      " Training time: 272.40 seconds\n",
      " ROC AUC Score (train): 0.7840 \n",
      " ROC AUC Score (Test): 0.7381 \n",
      " Difference AUC: 0.0460 \n",
      " F1 Score: 0.2825 \n",
      " Precision Score: 0.2010 \n",
      " Recall Score: 0.4751 \n",
      "\n",
      " Evaluate combination: 015/61 (global 14):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 2\n",
      "  max_features: 0.6\n",
      "  class_weight: {0: 1, 1: 12}\n",
      " Training time: 269.38 seconds\n",
      " ROC AUC Score (train): 0.7858 \n",
      " ROC AUC Score (Test): 0.7386 \n",
      " Difference AUC: 0.0472 \n",
      " F1 Score: 0.2587 \n",
      " Precision Score: 0.1624 \n",
      " Recall Score: 0.6353 \n",
      "\n",
      " Evaluate combination: 016/61 (global 15):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 2\n",
      "  max_features: 0.7\n",
      "  class_weight: balanced\n",
      " Training time: 312.59 seconds\n",
      " ROC AUC Score (train): 0.7860 \n",
      " ROC AUC Score (Test): 0.7384 \n",
      " Difference AUC: 0.0476 \n",
      " F1 Score: 0.2634 \n",
      " Precision Score: 0.1673 \n",
      " Recall Score: 0.6197 \n",
      "\n",
      " Evaluate combination: 017/61 (global 16):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 2\n",
      "  max_features: 0.7\n",
      "  class_weight: {0: 1, 1: 8}\n",
      " Training time: 310.95 seconds\n",
      " ROC AUC Score (train): 0.7848 \n",
      " ROC AUC Score (Test): 0.7382 \n",
      " Difference AUC: 0.0465 \n",
      " F1 Score: 0.2823 \n",
      " Precision Score: 0.2012 \n",
      " Recall Score: 0.4726 \n",
      "\n",
      " Evaluate combination: 018/61 (global 17):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 2\n",
      "  max_features: 0.7\n",
      "  class_weight: {0: 1, 1: 12}\n",
      " Training time: 312.29 seconds\n",
      " ROC AUC Score (train): 0.7865 \n",
      " ROC AUC Score (Test): 0.7382 \n",
      " Difference AUC: 0.0483 \n",
      " F1 Score: 0.2579 \n",
      " Precision Score: 0.1621 \n",
      " Recall Score: 0.6315 \n",
      "\n",
      " Evaluate combination: 019/61 (global 18):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 3\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.5\n",
      "  class_weight: balanced\n",
      " Training time: 224.75 seconds\n",
      " ROC AUC Score (train): 0.7842 \n",
      " ROC AUC Score (Test): 0.7386 \n",
      " Difference AUC: 0.0457 \n",
      " F1 Score: 0.2625 \n",
      " Precision Score: 0.1664 \n",
      " Recall Score: 0.6216 \n",
      "\n",
      " Evaluate combination: 020/61 (global 19):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 3\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.5\n",
      "  class_weight: {0: 1, 1: 8}\n",
      " Training time: 226.43 seconds\n",
      " ROC AUC Score (train): 0.7826 \n",
      " ROC AUC Score (Test): 0.7381 \n",
      " Difference AUC: 0.0446 \n",
      " F1 Score: 0.2838 \n",
      " Precision Score: 0.2017 \n",
      " Recall Score: 0.4786 \n",
      " New model found! (F1: 0.2838)\n",
      "\n",
      " Evaluate combination: 021/61 (global 20):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 3\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.5\n",
      "  class_weight: {0: 1, 1: 12}\n",
      " Training time: 227.94 seconds\n",
      " ROC AUC Score (train): 0.7839 \n",
      " ROC AUC Score (Test): 0.7382 \n",
      " Difference AUC: 0.0457 \n",
      " F1 Score: 0.2576 \n",
      " Precision Score: 0.1615 \n",
      " Recall Score: 0.6369 \n",
      "\n",
      " Evaluate combination: 022/61 (global 21):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 3\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.6\n",
      "  class_weight: balanced\n",
      " Training time: 299.53 seconds\n",
      " ROC AUC Score (train): 0.7853 \n",
      " ROC AUC Score (Test): 0.7382 \n",
      " Difference AUC: 0.0471 \n",
      " F1 Score: 0.2617 \n",
      " Precision Score: 0.1661 \n",
      " Recall Score: 0.6172 \n",
      "\n",
      " Evaluate combination: 023/61 (global 22):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 3\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.6\n",
      "  class_weight: {0: 1, 1: 8}\n",
      " Training time: 261.86 seconds\n",
      " ROC AUC Score (train): 0.7841 \n",
      " ROC AUC Score (Test): 0.7381 \n",
      " Difference AUC: 0.0459 \n",
      " F1 Score: 0.2818 \n",
      " Precision Score: 0.2005 \n",
      " Recall Score: 0.4745 \n",
      "\n",
      " Evaluate combination: 024/61 (global 23):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 3\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.6\n",
      "  class_weight: {0: 1, 1: 12}\n",
      " Training time: 262.50 seconds\n",
      " ROC AUC Score (train): 0.7853 \n",
      " ROC AUC Score (Test): 0.7383 \n",
      " Difference AUC: 0.0469 \n",
      " F1 Score: 0.2588 \n",
      " Precision Score: 0.1624 \n",
      " Recall Score: 0.6369 \n",
      "\n",
      " Evaluate combination: 025/61 (global 24):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 3\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.7\n",
      "  class_weight: balanced\n",
      " Training time: 298.91 seconds\n",
      " ROC AUC Score (train): 0.7860 \n",
      " ROC AUC Score (Test): 0.7391 \n",
      " Difference AUC: 0.0469 \n",
      " F1 Score: 0.2634 \n",
      " Precision Score: 0.1673 \n",
      " Recall Score: 0.6194 \n",
      "\n",
      " Evaluate combination: 026/61 (global 25):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 3\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.7\n",
      "  class_weight: {0: 1, 1: 8}\n",
      " Training time: 323.27 seconds\n",
      " ROC AUC Score (train): 0.7849 \n",
      " ROC AUC Score (Test): 0.7381 \n",
      " Difference AUC: 0.0468 \n",
      " F1 Score: 0.2814 \n",
      " Precision Score: 0.2003 \n",
      " Recall Score: 0.4726 \n",
      "\n",
      " Evaluate combination: 027/61 (global 26):\n",
      "  n_estimators: 150\n",
      "  max_depth: 8\n",
      "  min_samples_split: 3\n",
      "  min_samples_leaf: 1\n",
      "  max_features: 0.7\n",
      "  class_weight: {0: 1, 1: 12}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m  \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m  \u001b[49m\u001b[43minstance_id\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m  \u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m  \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m  \u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m  \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val_fold\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/anyone/assignment-sprint-02/src/grid_search.py:99\u001b[39m, in \u001b[36mgrid_search\u001b[39m\u001b[34m(params, instance_id, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     97\u001b[39m     \u001b[38;5;66;03m# Entrenar modelo con estos parámetros\u001b[39;00m\n\u001b[32m     98\u001b[39m     model = RandomForestClassifier(**params, random_state=\u001b[32m42\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# Evaluar en conjunto de validación\u001b[39;00m\n\u001b[32m    102\u001b[39m     train_preds = model.predict_proba(X_train_fold)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/anyone/assignment-sprint-02/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/anyone/assignment-sprint-02/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/anyone/assignment-sprint-02/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/anyone/assignment-sprint-02/.venv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/anyone/assignment-sprint-02/.venv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/anyone/assignment-sprint-02/.venv/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "grid_search(\n",
    "  params = param_grid,\n",
    "  instance_id=0, \n",
    "  X_train_fold=X_train_fold, \n",
    "  y_train_fold=y_train_fold, \n",
    "  X_val_fold=X_val_fold, \n",
    "  y_val_fold=y_val_fold\n",
    "  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2143f7b6",
   "metadata": {},
   "source": [
    "## 4. Predict unlabeled data\n",
    "\n",
    "Now it's time to finally use the `test_data` samples. Because we don't have the labels we can't see how the model performs on this dataset (╯°□°)╯︵ ┻━┻\n",
    "\n",
    "But... don't worry, we will internally evaluate your model and give feedback on the results!\n",
    "\n",
    "In the cells below:\n",
    "- Take your best model\n",
    "- Take `test_data` (i.e. the dataset after doing the preprocessing and feature engineering part)\n",
    "- Run the data through your model and save the predictions on the `TARGET` column in the `app_test` DataFrame (yeah that we've loaded at the very beginning of this notebook).\n",
    "    - `TARGET` column values must be the probabilities for class 1. So remember to use the `predict_proba()` function from your model as we did in the previous sections.\n",
    "- Save the modified version of the DataFrame with the same name it has before (`dataset/application_test_aai.csv`) and don't forget to submit it alongside the rest of this sprint project code\n",
    "- And finally, don't get confused, you shouldn't submit `dataset/application_train_aai.csv`. So please don't upload your solution with this heavy dataset inside.\n",
    "\n",
    "Let's say your best model is called `best_credit_model_ever`, then your code should be exactly this:\n",
    "\n",
    "```python\n",
    "    test_preds = best_credit_model_ever.predict_proba(test_data)[:, 1]\n",
    "    app_test[\"TARGET\"] = test_preds\n",
    "    app_test.to_csv(config.DATASET_TEST, index=False)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c99b20f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo final...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CalibratedClassifierCV.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:19\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: CalibratedClassifierCV.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 1. Definir el mejor modelo (ajustar al que encontraste como óptimo)\n",
    "best_model = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=8,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=0.5,\n",
    "    class_weight={0: 1, 1: 8},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Entrenarlo con tus datos de entrenamiento\n",
    "print(\"Entrenando el modelo final...\")\n",
    "best_model.fit(train_data, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ef3d480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score (Train): 0.7757\n",
      "ROC AUC Score (Validation): 0.7752\n",
      "Umbral óptimo: 0.1500 (F1 en validación: 0.2926)\n",
      "Generando predicciones para datos de prueba...\n",
      "Rango de probabilidades predecidas: [0.0170, 0.4625]\n",
      "Promedio de probabilidades: 0.0805\n",
      "Guardando predicciones...\n",
      "¡Predicciones guardadas exitosamente!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Calibrar probabilidades para mejorar estimaciones\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Usar el parámetro correcto según la versión de scikit-learn\n",
    "try:\n",
    "    # Para versiones más recientes (scikit-learn >= 1.0)\n",
    "    calibrated_model = CalibratedClassifierCV(\n",
    "        estimator=best_model,\n",
    "        method='sigmoid',\n",
    "        cv=5\n",
    "    )\n",
    "except TypeError:\n",
    "    # Para versiones anteriores (scikit-learn < 1.0)\n",
    "    calibrated_model = CalibratedClassifierCV(\n",
    "        base_estimator=best_model,\n",
    "        method='sigmoid',\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "calibrated_model.fit(train_data, y_train)\n",
    "\n",
    "y_train_pred = calibrated_model.predict(X_train_fold)\n",
    "y_val_pred = calibrated_model.predict(X_val_fold)\n",
    "\n",
    "# Si deseas obtener las probabilidades para la clase 1\n",
    "y_train_pred_proba = calibrated_model.predict_proba(X_train_fold)[:, 1]\n",
    "y_val_pred_proba = calibrated_model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "# Evaluar el modelo (opcional)\n",
    "roc_auc_train = roc_auc_score(y_train_fold, y_train_pred_proba)\n",
    "roc_auc_val = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
    "\n",
    "print(f\"ROC AUC Score (Train): {roc_auc_train:.4f}\")\n",
    "print(f\"ROC AUC Score (Validation): {roc_auc_val:.4f}\")\n",
    "\n",
    "# 4. Opcional: Encontrar umbral óptimo en validación\n",
    "# Nota: solo para referencia - no afecta las probabilidades guardadas\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "val_probs = calibrated_model.predict_proba(val_data)[:, 1]\n",
    "thresholds = np.arange(0.05, 0.5, 0.01)\n",
    "best_f1 = 0\n",
    "best_threshold = 0.5\n",
    "\n",
    "for threshold in thresholds:\n",
    "    val_preds = (val_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_val, val_preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"Umbral óptimo: {best_threshold:.4f} (F1 en validación: {best_f1:.4f})\")\n",
    "\n",
    "# 5. Predecir en los datos de prueba (usando el modelo calibrado)\n",
    "print(\"Generando predicciones para datos de prueba...\")\n",
    "test_preds = calibrated_model.predict_proba(test_data)[:, 1]\n",
    "\n",
    "# 6. Guardar predicciones en app_test\n",
    "app_test[\"TARGET\"] = test_preds\n",
    "\n",
    "# 7. Verificar rango de probabilidades (control de calidad)\n",
    "print(f\"Rango de probabilidades predecidas: [{test_preds.min():.4f}, {test_preds.max():.4f}]\")\n",
    "print(f\"Promedio de probabilidades: {test_preds.mean():.4f}\")\n",
    "\n",
    "# 8. Guardar el DataFrame modificado\n",
    "print(\"Guardando predicciones...\")\n",
    "app_test.to_csv(config.DATASET_TEST, index=False)\n",
    "print(\"¡Predicciones guardadas exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad777cd",
   "metadata": {},
   "source": [
    "## 5. Optional exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e7335-f3cc-410d-81f2-f110f3fbb252",
   "metadata": {
    "id": "d72e7335-f3cc-410d-81f2-f110f3fbb252"
   },
   "source": [
    "### Optional: Training a LightGBM model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015d58b7-9f70-4bfb-8b72-20a626e00ea0",
   "metadata": {
    "id": "015d58b7-9f70-4bfb-8b72-20a626e00ea0"
   },
   "source": [
    "5.1. Gradient Boosting Machine is one of the most used machine learning algorithms for tabular data. Lots of competitions have been won using models from libraries like XGBoost or LightGBM. You can try using [LightGBM](https://lightgbm.readthedocs.io/en/latest/) to train a new model an see how it performs compared to the other classifiers you trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d497eb-2b8b-43fe-945e-26a04b8fc004",
   "metadata": {
    "id": "91d497eb-2b8b-43fe-945e-26a04b8fc004"
   },
   "outputs": [],
   "source": [
    "### Complete in this cell: train a LightGBM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d1a1f4-5e1e-4982-a6ae-a27b8c11428e",
   "metadata": {
    "id": "c2d1a1f4-5e1e-4982-a6ae-a27b8c11428e"
   },
   "source": [
    "### Optional: Using Scikit Learn Pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f95fb-73bf-42c4-97a3-80078f2496aa",
   "metadata": {
    "id": "2e4f95fb-73bf-42c4-97a3-80078f2496aa"
   },
   "source": [
    "5.2. So far you've created special functions or blocks or code to chain operations on data and then train the models. But, reproducibility is important, and you don't want to have to remember the correct steps to follow each time you have new data to train your models. There are a lots of tools out there that can help you with that, here you can use a [Sklearn Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) to process your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5eecdf-ee08-4ebd-8667-25cdb9a3eef4",
   "metadata": {
    "id": "5a5eecdf-ee08-4ebd-8667-25cdb9a3eef4"
   },
   "outputs": [],
   "source": [
    "### Complete in this cell: use a sklearn Pipeline to automate the cleaning, standardizing and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fcadf8",
   "metadata": {},
   "source": [
    "### Optional: Build your own model and features\n",
    "\n",
    "5.3. If you want you can take the original labeled data given and make your own feature selection, data preprocessing, and model tunning. Be creative, the only limit is time and hardware resources. Only be careful and don't modify the previous functions made in the mandatory assignments or, you will break the project tests.\n",
    "\n",
    "You can even use this newer model to make predictions in the test dataset with hidden labels and submit that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942da44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete in this cell: Make you own experimentation process"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
